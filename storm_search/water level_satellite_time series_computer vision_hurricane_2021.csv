title,abstract,year,citationCount,url,paperId,authors
A Novel Approach to Estimating Time-Averaged Volcanic SO2 Fluxes from Infrared Satellite Measurements,"Long-term continuous time series of SO2 emissions are considered critical elements of both volcano monitoring and basic research into processes within magmatic systems. One highly successful framework for computing these fluxes involves reconstructing a representative time-averaged SO2 plume from which to estimate the SO2 source flux. Previous methods within this framework have used ancillary wind datasets from reanalysis or numerical weather prediction (NWP) to construct the mean plume and then again as a constrained parameter in the fitting. Additionally, traditional SO2 datasets from ultraviolet (UV) sensors lack altitude information, which must be assumed, to correctly calibrate the SO2 data and to capture the appropriate NWP wind level which can be a significant source of error. We have made novel modifications to this framework which do not rely on prior knowledge of the winds and therefore do not inherit errors associated with NWP winds. To perform the plume rotation, we modify a rudimentary computer vision algorithm designed for object detection in medical imaging to detect plume-like objects in gridded SO2 data. We then fit a solution to the general time-averaged dispersion of SO2 from a point source. We demonstrate these techniques using SO2 data generated by a newly developed probabilistic layer height and column loading algorithm designed for the Cross-track Infrared Sounder (CrIS), a hyperspectral infrared sensor aboard the Joint Polar Satellite Systemâ€™s Suomi-NPP and NOAA-20 satellites. This SO2 data source is best suited to flux estimates at high-latitude volcanoes and at low-latitude, but high-altitude volcanoes. Of particular importance, IR SO2 data can fill an important data gap in the UV-based record: estimating SO2 emissions from high-latitude volcanoes through the polar winters when there is insufficient solar backscatter for UV sensors to be used.",2021,2,https://www.semanticscholar.org/paper/128082bab02a44915b70c9d12749e29ef02a3712,128082bab02a44915b70c9d12749e29ef02a3712,"D. Hyman, M. Pavolonis, J. Sieglaff"
Damaged Building Detection from Satellite Multispectral Imagery,"Damaged Building footprint detection in satellite and aerial imagery is crucial in city management. Building detection is a fundamental but a challenging problem mainly because it requires correct recovery of building footprints from high-resolution images. Buildings are one of the key pieces of cadastral information related to population and cities, and are fundamental to urban planning & policymaking. Critical infrastructures, such as public transport, electricity, water distribution networks, or postal and delivery services, rely heavily on accurate population and building maps. On top of that, it is essential to get real-life, up-to-date information about buildings each time there is a need for disaster risk management, risk assessment, or emergency relief. Accurate and fine-grained information about the extent of damage to buildings is essential for directing Humanitarian Aid and Disaster Response operations in the immediate aftermath of any natural calamity. Satellite and UAV (drone) imagery has been used for this purpose in recent years, sometimes aided by computer vision algorithms. Existing Computer Vision approaches for building damage assessment typically rely on a two stage approach, consisting of building detection using an object detection model, followed by damage assessment through classification of the detected building tiles. These multi-stage methods are not end-to-end trainable, and as well as suffer from poor overall results. We proposed the UNet segmentation model, a model that can simultaneously segment buildings and assess the damage levels to individual buildings and can be trained end-to-end. We trained the model using X View 2 challenge dataset.",2021,0,https://www.semanticscholar.org/paper/01f32766cc799b68a1f945c874f6bb570b69de37,01f32766cc799b68a1f945c874f6bb570b69de37,A. Sangeetha
