{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping from Science Direct\n",
    "\n",
    "The current problem is the abstract information is not shown in the html file downloaded. So we need to add them manually afterwards.\n",
    "\n",
    "To get around of blocking access: download the corresponding html page, and then use the functions below to filter data out.\n",
    "\n",
    "We remove publications that has 'index' as title (index page is not our interests), and also the one begin with 'Chapter' (book contains no new data).\n",
    "\n",
    "The functions below gather the title, author, year of publication and url to the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles found: 12\n",
      "Title: Molecular and functional basis of high-salt avoidance in a blood-sucking insect\n",
      "Authors: Gina Pontes, José Manuel Latorre-Estivalis, Romina B. Barrozo\n",
      "URL: https://www.sciencedirect.com/science/article/pii/S2589004222007738/pdfft?md5=270c1185f1670c2a6bee15f01e5dddb6&pid=1-s2.0-S2589004222007738-main.pdf\n",
      "Year: 2022\n",
      "\n",
      "Title: Chapter 8: Panics and pandemics\n",
      "Authors: Edward P. Rybicki\n",
      "URL: No URL found\n",
      "Year: 2023\n",
      "\n",
      "Title: 69: Immunologic Mechanisms ofAtherosclerosis and Myocarditis\n",
      "Authors: Peter Libby, Andrew H. Lichtman\n",
      "URL: https://www.sciencedirect.com/science/article/pii/B9780702081651000691/pdfft?md5=60e48666196b29fd3bb9e8af00780746&pid=3-s2.0-B9780702081651000691-main.pdf\n",
      "Year: 2023\n",
      "\n",
      "Title: Structure-based design, synthesis and evaluation of a novel family of PEX5-PEX14 interaction inhibitors againstTrypanosoma\n",
      "Authors: Valeria Napolitano, Piotr Mróz, Grzegorz Dubin\n",
      "URL: https://www.sciencedirect.com/science/article/pii/S0223523422006808/pdfft?md5=ad1ea5fe27759367698e0e7b61273651&pid=1-s2.0-S0223523422006808-main.pdf\n",
      "Year: 2022\n",
      "\n",
      "Title: The hormonal and neural control of egg production in the historically important model insect,Rhodnius prolixus: A review, with new insights in this post-genomic era\n",
      "Authors: Angela B. Lange, Jimena Leyria, Ian Orchard\n",
      "URL: https://www.sciencedirect.com/science/article/pii/S0016648022000557/pdfft?md5=8f9ed41081913b241087270432a9a554&pid=1-s2.0-S0016648022000557-main.pdf\n",
      "Year: 2022\n",
      "\n",
      "Title: Anti-Parasite Agents and Vaccines\n",
      "Authors: Rashika El Ridi\n",
      "URL: https://www.sciencedirect.com/science/article/pii/B9780128187319000963/pdfft?md5=717cb726b47b8d90d98cbfdbaff597c9&pid=3-s2.0-B9780128187319000963-main.pdf\n",
      "Year: 2022\n",
      "\n",
      "Title: Chapter 4: Trypanosomiasis\n",
      "Authors: Benoit Stijlemans, Boyoon Choi, Stefan Magez\n",
      "URL: https://www.sciencedirect.com/science/article/pii/B9780443191619000048/pdfft?md5=26235c4ad61bdc5e4cf335f1cfca42dc&pid=3-s2.0-B9780443191619000048-main.pdf\n",
      "Year: 2024\n",
      "\n",
      "Title: Parasites of the Gastrointestinal Tract\n",
      "Authors: Blaine A. Mathison, Bobbi S. Pritt\n",
      "URL: https://www.sciencedirect.com/science/article/pii/B9780128187319001075/pdfft?md5=309290dfd07b62606a813e851ac2eb9e&pid=3-s2.0-B9780128187319001075-main.pdf\n",
      "Year: 2022\n",
      "\n",
      "Title: Drug resistance in animal trypanosomiases: Epidemiology, mechanisms and control strategies\n",
      "Authors: Marzuq A. Ungogo, Harry P. de Koning\n",
      "URL: https://www.sciencedirect.com/science/article/pii/S2211320724000149/pdfft?md5=bfe511b8f01007efd11880ee75b2289f&pid=1-s2.0-S2211320724000149-main.pdf\n",
      "Year: 2024\n",
      "\n",
      "Title: Chapter 3: Specific Infectious Diseases\n",
      "Authors: Daniel S. Burns, Lucy Lamb\n",
      "URL: https://www.sciencedirect.com/science/article/pii/B9780323794121000035/pdfft?md5=9ea5896e02b65bd333f15bcb4b4186f4&pid=3-s2.0-B9780323794121000035-main.pdf\n",
      "Year: 2023\n",
      "\n",
      "Data saved to /Users/liting/Documents/GitHub/google-scholar-search/science-direct/Mexico2_data.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_titles_authors_urls_years_from_html(file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        articles = soup.find_all('div', class_='result-item-container')\n",
    "        print(\"Number of articles found:\", len(articles))\n",
    "\n",
    "        for article in articles:\n",
    "            try:\n",
    "                title_element = article.select_one('span.anchor-text > span')\n",
    "                title = title_element.get_text(strip=True) if title_element else 'No title found'\n",
    "                # Skip storing the article if the title is \"Index\"\n",
    "                if title == 'Index':\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                title = 'No title found'\n",
    "                print(f\"Title Error: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Check for authors in both possible classes\n",
    "                authors_elements = article.select('ol.Authors.hor.reduce-list li span.author')\n",
    "                if not authors_elements:\n",
    "                    authors_elements = article.select('ol.Authors.hor li span.author')\n",
    "                authors = ', '.join([author.get_text(strip=True) for author in authors_elements])\n",
    "            except Exception as e:\n",
    "                authors = 'No authors found'\n",
    "                print(f\"Authors Error: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Find the URL in the PreviewLinks div\n",
    "                url_element = article.select_one('div.PreviewLinks a')\n",
    "                url = url_element['href'] if url_element else 'No URL found'\n",
    "            except Exception as e:\n",
    "                url = 'No URL found'\n",
    "                print(f\"URL Error: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Find the year in the srctitle-date-fields span\n",
    "                year_element = article.select_one('span.srctitle-date-fields')\n",
    "                if year_element:\n",
    "                    year_text = year_element.get_text(strip=True)\n",
    "                    year = year_text[-4:]  # The year is the last four characters of the text\n",
    "                else:\n",
    "                    year = 'No year found'\n",
    "            except Exception as e:\n",
    "                year = 'No year found'\n",
    "                print(f\"Year Error: {e}\")\n",
    "\n",
    "            # Add the extracted title, authors, URL, and year to the data list\n",
    "            data.append({\n",
    "                'title': title,\n",
    "                'authors': authors,\n",
    "                'url': url,\n",
    "                'year': year\n",
    "            })\n",
    "\n",
    "            # Debug: Print the extracted information for each article\n",
    "            print(f\"Title: {title}\\nAuthors: {authors}\\nURL: {url}\\nYear: {year}\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    country_name = 'Mexico2'\n",
    "    file_path = '/Users/liting/Desktop/Triatomine'+country_name+'.html' #replace it with the path of the html file you downloaded\n",
    "    data = get_titles_authors_urls_years_from_html(file_path)\n",
    "    save_file_path = '/Users/liting/Documents/GitHub/google-scholar-search/science-direct/'+country_name+'_data.csv' #where you want to save the csv file\n",
    "    save_to_csv(data,save_file_path)\n",
    "    print(f'Data saved to /Users/liting/Documents/GitHub/google-scholar-search/science-direct/'+country_name+'_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: /Users/liting/Documents/GitHub/google-scholar-search/science-direct/Mexico2_data.csv\n",
      "Reading file: /Users/liting/Documents/GitHub/google-scholar-search/science-direct/UnitedStates_data.csv\n",
      "Reading file: /Users/liting/Documents/GitHub/google-scholar-search/science-direct/Mexico_data.csv\n",
      "Reading file: /Users/liting/Documents/GitHub/google-scholar-search/science-direct/Canada_data.csv\n",
      "Duplicates saved to /Users/liting/Documents/GitHub/google-scholar-search/science-direct/duplication.csv\n",
      "Uniques saved to /Users/liting/Documents/GitHub/google-scholar-search/science-direct/unique.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_csv_files(directory_path):\n",
    "    # List to hold dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\"data.csv\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Reading file: {file_path}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove rows where titles begin with 'Chapter'\n",
    "    combined_df = combined_df[~combined_df['title'].str.startswith('Chapter', na=False)]\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def compare_titles(combined_df, reference_file, unique_file, duplication_file):\n",
    "    reference_df = pd.read_csv(reference_file)\n",
    "\n",
    "    # Identify duplicates\n",
    "    duplicates = combined_df[combined_df['title'].isin(reference_df['title'])]\n",
    "    uniques = combined_df[~combined_df['title'].isin(reference_df['title'])]\n",
    "\n",
    "    # Save duplicates and uniques to separate CSV files\n",
    "    duplicates.to_csv(duplication_file, index=False)\n",
    "    uniques.to_csv(unique_file, index=False)\n",
    "    print(f'Duplicates saved to {duplication_file}')\n",
    "    print(f'Uniques saved to {unique_file}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    directory_path = '/Users/liting/Documents/GitHub/google-scholar-search/science-direct/'\n",
    "    reference_file = '/Users/liting/Documents/GitHub/google-scholar-search/science-direct/reference.csv'\n",
    "    unique_file = '/Users/liting/Documents/GitHub/google-scholar-search/science-direct/unique.csv'\n",
    "    duplication_file = '/Users/liting/Documents/GitHub/google-scholar-search/science-direct/duplication.csv'\n",
    "\n",
    "    combined_df = combine_csv_files(directory_path)\n",
    "    compare_titles(combined_df, reference_file, unique_file, duplication_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
