{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from requests import Session\n",
    "from typing import Generator, Union\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_API_KEY = 'XBbGPcpPXB5CH0aLSu6BO5fww06zAusz6dFGXqj0'\n",
    "\n",
    "def get_paper(session: Session, paper_id: str, fields: str = 'paperId,title', **kwargs) -> dict:\n",
    "    params = {\n",
    "        'fields': fields,\n",
    "        **kwargs,\n",
    "    }\n",
    "    headers = {\n",
    "        'x-api-key': S2_API_KEY,\n",
    "    }\n",
    "\n",
    "    with session.get(f'https://api.semanticscholar.org/graph/v1/paper/{paper_id}', params=params, headers=headers) as response:\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "def download_pdf(session: Session, url: str, path: str, user_agent: str = 'requests/2.0.0'):\n",
    "    # send a user-agent to avoid server error\n",
    "    headers = {\n",
    "        'user-agent': user_agent,\n",
    "    }\n",
    "\n",
    "    # stream the response to avoid downloading the entire file into memory\n",
    "    with session.get(url, headers=headers, stream=True, verify=False) as response:\n",
    "        # check if the request was successful\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.headers['content-type'] != 'application/pdf':\n",
    "            raise Exception('The response is not a pdf')\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            # write the response to the file, chunk_size bytes at a time\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "def download_paper(session: Session, paper_id: str, directory: str = 'papers', user_agent: str = 'requests/2.0.0') -> Union[str, None]:\n",
    "    paper = get_paper(session, paper_id, fields='paperId,isOpenAccess,openAccessPdf')\n",
    "\n",
    "    # check if the paper is open access\n",
    "    if not paper['isOpenAccess']:\n",
    "        return None\n",
    "\n",
    "    paperId: str = paper['paperId']\n",
    "    pdf_url: str = paper['openAccessPdf']['url']\n",
    "    pdf_path = os.path.join(directory, f'{paperId}.pdf')\n",
    "\n",
    "    # create the directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # check if the pdf has already been downloaded\n",
    "    if not os.path.exists(pdf_path):\n",
    "        download_pdf(session, pdf_url, pdf_path, user_agent=user_agent)\n",
    "\n",
    "    return pdf_path\n",
    "\n",
    "\n",
    "def download_papers(paper_ids: list[str], directory: str = 'papers', user_agent: str = 'requests/2.0.0') -> Generator[tuple[str, Union[str, None, Exception]], None, None]:\n",
    "    # use a session to reuse the same TCP connection\n",
    "    with Session() as session:\n",
    "        for paper_id in paper_ids:\n",
    "            try:\n",
    "                yield paper_id, download_paper(session, paper_id, directory=directory, user_agent=user_agent)\n",
    "            except Exception as e:\n",
    "                yield paper_id, e\n",
    "\n",
    "\n",
    "def semanticscholardownload(paper_ids,download_paper_path):\n",
    "    for paper_id, result in download_papers(paper_ids, directory=download_paper_path, user_agent='requests/2.0.0'):\n",
    "        if isinstance(result, Exception):\n",
    "            return (f\"Failed to download '{paper_id}': {type(result).__name__}: {result}\")\n",
    "        elif result is None:\n",
    "            return (f\"'{paper_id}' is not open access\")\n",
    "        else:\n",
    "            return (f\"Downloaded '{paper_id}' to '{result}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list_csv_path = '/Users/vivianhuang/Desktop/CHG/coastal%20surge_texas_south_model.csv'\n",
    "paper_list_df = pd.read_csv(paper_list_csv_path)\n",
    "\n",
    "new_paper_list = paper_list_df.copy()\n",
    "new_paper_list_len = len(new_paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_paper_dir = '/Users/vivianhuang/Desktop/CHG/papers/'\n",
    "search_in_paper = ['bathymetry gradient','bottom stress','atmospheric pressure gradient','tides','radiation stress']\n",
    "for this_keyword in search_in_paper:\n",
    "    new_paper_list[this_keyword]=np.nan\n",
    "\n",
    "new_paper_list['pdf open access']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "This pdf is not open access.\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rl/b_rhkl_n5bn9m_27ts9r5rjc0000gn/T/ipykernel_38808/3572141692.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_paper_list['pdf open access'][i] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This pdf is not open access.\n",
      "2\n",
      "This pdf is not open access.\n",
      "3\n",
      "Failed to download\n",
      "4\n",
      "This pdf is not open access.\n",
      "5\n",
      "Downloaded 'b4877795b435e69452af8b35fa3bf1086585e7db' to '/Users/vivianhuang/Desktop/CHG/papers/b4877795b435e69452af8b35fa3bf1086585e7db.pdf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rl/b_rhkl_n5bn9m_27ts9r5rjc0000gn/T/ipykernel_38808/3572141692.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_paper_list[this_keyword][i]=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "This pdf is not open access.\n",
      "7\n",
      "Downloaded '13b5c916ccbd7b5bf0d061f1b90b9f88e773bd1f' to '/Users/vivianhuang/Desktop/CHG/papers/13b5c916ccbd7b5bf0d061f1b90b9f88e773bd1f.pdf'\n",
      "8\n",
      "Downloaded '2ca75c2aa3a7a77f35126103f9b9875abb29ebf9' to '/Users/vivianhuang/Desktop/CHG/papers/2ca75c2aa3a7a77f35126103f9b9875abb29ebf9.pdf'\n",
      "9\n",
      "This pdf is not open access.\n",
      "10\n",
      "This pdf is not open access.\n",
      "11\n",
      "This pdf is not open access.\n",
      "12\n",
      "This pdf is not open access.\n",
      "13\n",
      "Downloaded '3a050df72cee3db45c0da0079cbe0124a295d08c' to '/Users/vivianhuang/Desktop/CHG/papers/3a050df72cee3db45c0da0079cbe0124a295d08c.pdf'\n",
      "14\n",
      "This pdf is not open access.\n",
      "15\n",
      "Failed to download\n",
      "16\n",
      "Downloaded '64e5521f09fcc6107b0e099397738f92be8c81cd' to '/Users/vivianhuang/Desktop/CHG/papers/64e5521f09fcc6107b0e099397738f92be8c81cd.pdf'\n",
      "17\n",
      "This pdf is not open access.\n",
      "18\n",
      "This pdf is not open access.\n",
      "19\n",
      "This pdf is not open access.\n",
      "20\n",
      "This pdf is not open access.\n",
      "21\n",
      "Downloaded '3f98dff78c97ddff10996c478f4ab69d8ea16b8e' to '/Users/vivianhuang/Desktop/CHG/papers/3f98dff78c97ddff10996c478f4ab69d8ea16b8e.pdf'\n",
      "22\n",
      "This pdf is not open access.\n",
      "23\n",
      "This pdf is not open access.\n",
      "24\n",
      "This pdf is not open access.\n",
      "25\n",
      "This pdf is not open access.\n",
      "26\n",
      "Downloaded '2e82610bfb054e07203673ba27e015e53b87f63c' to '/Users/vivianhuang/Desktop/CHG/papers/2e82610bfb054e07203673ba27e015e53b87f63c.pdf'\n",
      "27\n",
      "Downloaded '7b4b25fcc4c273596fdc8e8fe1e092e6cba95615' to '/Users/vivianhuang/Desktop/CHG/papers/7b4b25fcc4c273596fdc8e8fe1e092e6cba95615.pdf'\n",
      "28\n",
      "This pdf is not open access.\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for i in range(new_paper_list_len):\n",
    "    print(i)\n",
    "    output = semanticscholardownload([new_paper_list['paperId'][i]],download_paper_dir)\n",
    "    #'python simple.py -d papers '+new_paper_list['paperId'][i]#'python simple.py -d papers 649def34f8be52c8b66281af98ae884c09aef38b'\n",
    "    \n",
    "    if ' is not open access' in output:\n",
    "        print('This pdf is not open access.')\n",
    "        new_paper_list['pdf open access'][i] = False\n",
    "        continue\n",
    "\n",
    "    if 'Failed to download' in output:\n",
    "        print('Failed to download')\n",
    "        new_paper_list['pdf open access'][i] = False\n",
    "        continue\n",
    "\n",
    "    new_paper_list['pdf open access'][i] = True\n",
    "    print(output)\n",
    "    # open the pdf file\n",
    "    download_paper_path = download_paper_dir +new_paper_list['paperId'][i]+'.pdf'\n",
    "    \n",
    "\n",
    "    reader = PdfReader(download_paper_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()   \n",
    "        res_search = re.search('references\\n', text, re.IGNORECASE)\n",
    "        if  type(res_search).__name__ != 'NoneType':\n",
    "            text=re.split('references\\n',page.extract_text(),flags=re.IGNORECASE)[0]\n",
    "\n",
    "        for this_keyword in search_in_paper:\n",
    "            res_search = re.search(this_keyword, text, re.IGNORECASE)\n",
    "            if type(res_search).__name__ != 'NoneType':\n",
    "                new_paper_list[this_keyword][i]=True \n",
    "\n",
    "        \n",
    "    \n",
    "    os.remove(download_paper_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paper_list.to_csv(download_paper_path[:-4]+'.csv', sep=',', index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
